% This file was created with JabRef 2.4.2.
% Encoding: Cp1252

@INCOLLECTION{BZ05,
  author = {Anthony J. Bagnall and Zhanna V. Zatuchna},
  title = {On the classification of {M}aze problems},
  booktitle = {Foundations of Learning Classifier Systems},
  publisher = {Springer},
  year = {2005},
  volume = {183},
  series = {Studies in Fuzziness and Soft Computing},
  pages = {305--316},
  abstract = {A maze is a grid-like two-dimensional area of any size, usually rectangular.
	A maze consists of cells. A cell is an elementary maze item, a formally
	bounded space, interpreted as a single site. The maze may contain
	different obstacles in any quantity. Some may be significant for
	learning purposes, like virtual food. The agent is randomly placed
	in the maze on an empty cell. The agent is allowed to move in all
	directions, but only through empty space. The task is to learn a
	policy to reach food as fast as possible from any square. Once the
	food is reached, the agent position is reset to a random one and
	the task repeated.},
  doi = {10.1007/11319122_12},
  owner = {Richter},
  timestamp = {2009.04.11}
}

@TECHREPORT{BJD86,
  author = {Miroslav Benda and Vasudevan Jagannathan and Rajendra Dodhiawala},
  title = {An optimal cooperation of knowledge sources: An empirical investigation},
  institution = {Boeing Advanced Technology Center, Boeing Computing Services},
  year = {1986},
  number = {BCS-{\-}G2010--{\-}28},
  address = {Seattle, Washington, United States of America},
}

@ARTICLE{Bresenham,
  author = {J.E. Bresenham},
  title = {Algorithm for Computer Control of a Digital Plotter},
  journal = {IBM Systems J.},
  year = {1965},
  volume = {4},
  pages = {25--30},
  number = {1}
}

@TECHREPORT{Bull03asimple,
  author = {Larry Bull},
  title = {A Simple Accuracy-based Learning Classifier System},
  institution = {Learning Classifier Systems Group Technical Report UWELCSG03-005},
  year = {2003},
  url = {http://www2.cmp.uea.ac.uk/~it/ycs/ycs.pdf}
}

@INBOOK{Butz2006,
  chapter = {4},
  pages = {51--64},
  title = {The XCS Classifier System},
  publisher = {Springer},
  year = {2006},
  author = {Martin V. Butz},
  booktitle = {In Studies in Fuzziness and Soft Computing}
}

@INBOOK{Butz2006a,
  chapter = {4},
  pages = {31--50},
  title = {Simple Learning Classifier Systems},
  publisher = {Springer},
  year = {2006},
  author = {Martin V. Butz},
  booktitle = {In Studies in Fuzziness and Soft Computing}
}

@TECHREPORT{But00,
  author = {Martin V. Butz},
  title = {{XCSJ}ava 1.0: An implementation of the {XCS} classifier system in
	{J}ava},
  institution = {Illinois Genetic Algorithms Laboratory},
  year = {2000},
  number = {2000027},
  owner = {Richter},
  timestamp = {2008.01.16},
  url = {ftp://ftp-illigal.ge.uiuc.edu/pub/papers/IlliGALs/2000027.ps.Z}
}

@MISC{Butz_xcsclassifier,
  author = {Martin V. Butz},
  title = {XCS classifier system in Java},
  year = {2000},
  url = {http://www.illigal.uiuc.edu/pub/papers/IlliGALs/2000027.ps.Z}
}

@ARTICLE{Butz2005,
  author = {Butz, M. V. and Goldberg, D. E. and Lanzi, P. L. },
  title = {Gradient descent methods in learning classifier systems: improving
	XCS performance in multistep problems},
  journal = {IEEE Transactions on Evolutionary Computation},
  year = {2005},
  volume = {9},
  pages = {452--473},
  number = {5},
}

@ARTICLE{BKLW04,
  author = {Martin V. Butz and Tim Kovacs and Pier Luca Lanzi and Stewart W.
	Wilson},
  title = {Toward a theory of generalisation and learning in {XCS}},
  journal = {IEEE Transactions on Evolutionary Computation},
  year = {2004},
  volume = {8},
  pages = {28--46},
  number = {1},
  abstract = {In this paper, we take initial steps toward a theory of generalization
	and learning in the learning classifier system XCS. We start fromWilson's
	generalization hypothesis, which states that XCS has an intrinsic
	tendency to evolve accurate, maximally general classifiers. We analyze
	the different evolutionary pressures in XCS and derive a simple equation
	that supports the hypothesis theoretically. The equation is tested
	with a number of experiments that confirm the model of generalization
	pressure that we provide. Then, we focus on the conditions, termed
	"challenges", that must be satisfied for the existence of effective
	fitness or accuracy pressure in XCS. We derive two equations that
	suggest how to set the population size and the covering probability
	so as to ensure the development of fitness pressure. We argue that
	when the challenges are met, XCS is able to evolve problem solutions
	reliably. When the challenges are not met, a problem may provide
	intrinsic fitness guidance or the reward may be biased in such a
	way that the problem will still be solved. The equations and the
	influence of intrinsic fitness guidance and biased reward are tested
	on large Boolean multiplexer problems. The paper is a contribution
	to understanding how XCS functions and lays the foundation for research
	on XCSs learning complexity.},
  doi = {10.1109/TEVC.2003.818194},
  owner = {Richter},
  timestamp = {2009.04.15}
}

@ARTICLE{BW02,
  author = {Martin V. Butz and Stewart W. Wilson},
  title = {An algorithmic description of {XCS}},
  journal = {Soft Computing},
  year = {2002},
  volume = {6},
  pages = {144--153},
  number = {3--4},
  abstract = {A concise description of the XCS classifier system's parameters, structures,
	and algorithms is presented as an aid to research. The algorithms
	are written in modularly structured pseudo code with accompanying
	explanations.},
  doi = {10.1007/s005000100111},
  owner = {Richter},
  timestamp = {2008.02.21}
}

@INPROCEEDINGS{DAL05a,
  author = {Hai H. Dam and Hussein A. Abbass and Chris Lokan},
  title = {Be real! {XCS} with continuous-valued inputs},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference
	(GECCO 2005)},
  year = {2005},
  pages = {85--87},
  address = {New York, United States of America},
  publisher = {ACM},
  abstract = {XCS is widely accepted as one of the most reliable Michigan-style
	learning classifier system (LCS) for data mining. In order to handle
	real-valued inputs effectively, the traditional ternary representation
	has been replaced by the interval-based representation and the modified
	XCS has shown to work well. Existing interval-based representations
	still suffer from a few drawbacks which this paper address. In this
	paper, we propose an alternative approach called the Min-Percentage
	representation which produces comparable results to other methods
	in the literature with the extra advantage of overcoming the drawbacks
	in these methods.},
  file = {DAL05a.pdf:Learning\\Learning Classifier Systems\\DAL05a.pdf:PDF},
  owner = {Richter},
  timestamp = {2008.01.16}
}

@ARTICLE{DeJ88,
  author = {Kenneth {De Jong}},
  title = {Learning with genetic algorithms: {A}n overview},
  journal = {Machine Learning},
  year = {1988},
  volume = {3},
  pages = {121--138},
  number = {2--3},
  abstract = {Genetic algorithms represent a class of adaptive search techniques
	that have been intensively studied in recent years. Much of the interest
	in genetic algorithms is due to the fact that they provide a set
	of efficient domain-independent search heuristics which are a significant
	improvement over traditional weak methods without the need for incorporating
	highly domain-specific knowledge. There is now considerable evidence
	that genetic algorithms are useful for global function optimization
	and NP-hard problems. Recently, there has been a good deal of interest
	in using genetic algorithms for machine learning problems. This paper
	provides a brief overview of how one might use genetic algorithms
	as a key element in learning systems.},
  doi = {10.1007/BF00113894},
  owner = {Richter},
  timestamp = {2009.04.07}
}

@MISC{gifencoder,
  author = {J. M. G. Elliott},
  title = {Gif89Encoder 0.90 beta},
  year = {2000},
  url = {http://jmge.net/java/gifenc/}
}

@INPROCEEDINGS{1102279,
  author = {Hamzeh,, Ali and Rahmani,, Adel},
  title = {Intelligent exploration method for XCS},
  booktitle = {GECCO '05: Proceedings of the 2005 workshops on Genetic and evolutionary
	computation},
  year = {2005},
  pages = {100--102},
  address = {New York, NY, USA},
  publisher = {ACM},
  location = {Washington, D.C.}
}

@INPROCEEDINGS{Hercog02socialsimulation,
  author = {Luis Miramontes Hercog and Terence C. Fogarty and London Se Aa},
  title = {Social simulation using a multi-agent model based on classifier systems:
	The emergence of vacillating behaviour in the "`el farol"' bar problem},
  booktitle = {Proceedings of the International Workshop in Learning Classifier
	Systems 2001},
  year = {2002},
  publisher = {Springer-Verlag}
}

@INCOLLECTION{Hol76,
  author = {John H. Holland},
  title = {Adaptation},
  booktitle = {Progress in Theoretical Biology},
  publisher = {Academic Press},
  year = {1976},
  volume = {4},
  pages = {263--293},
  address = {New York, NY, United States of America},
  owner = {Richter},
  timestamp = {2009.04.07}
}

@BOOK{Hol75,
  title = {Adaptation in natural and artificial systems},
  publisher = {University of Michigan Press},
  year = {1975},
  author = {John H. Holland},
  address = {Ann Arbor},
  owner = {Richter},
  timestamp = {2008.02.23}
}

@INCOLLECTION{HBC+00,
  author = {John H. Holland and Lashon B. Booker and Marco Colombetti and Marco
	Dorigo and David E. Goldberg and Stephanie Forrest and Rick L. Riolo
	and Robert E. Smith and Pier Luca Lanzi and Wolfgang Stolzmann and
	Stewart W. Wilson},
  title = {What is a learning classifier system?},
  booktitle = {Learning classifier systems: From foundations to applications},
  publisher = {Springer},
  year = {2000},
  volume = {1813},
  series = {LNAI},
  pages = {3--32},
  abstract = {We asked ``What is a Learning Classifier System'' to some of the best-known
	researchers in the field. These are their answers.},
  owner = {Richter},
  timestamp = {2007.10.09}
}

@INCOLLECTION{HR78,
  author = {John H. Holland and Judith S. Reitman},
  title = {Cognitive systems based on adaptive algorithms},
  booktitle = {Pattern-Directed Inference Systems},
  publisher = {Academic Press},
  year = {1978},
  pages = {313--329},
  owner = {Richter},
  timestamp = {2009.04.07}
}

@INPROCEEDINGS{1102281,
  author = {Inoue,, Hiroyasu and Takadama,, Keiki and Shimohara,, Katsunori},
  title = {Exploring XCS in multiagent environments},
  booktitle = {GECCO '05: Proceedings of the 2005 workshops on Genetic and evolutionary
	computation},
  year = {2005},
  pages = {109--111},
  address = {New York, NY, USA},
  publisher = {ACM},
  location = {Washington, D.C.}
}

@INPROCEEDINGS{Miyazaki2,
  author = {K. Miyazaki, M. Yamamura, S. Kobayashi},
  title = {On the rationality of profit sharing in multi-agent reinforcement
	learning},
  booktitle = {Fourth International Conference on Computational Intelligence and
	Multimedia Applications},
  year = {2001},
  pages = {123--127}
}

@INPROCEEDINGS{Miyazaki,
  author = {K. Miyazaki, M. Yamamura, S. Kobayashi},
  title = {On the rationality of profit sharing in reinforcement learning},
  booktitle = {Proceedings of the 3rd International Conference on Fuzzy Logic, Neural
	Nets and Soft Computing},
  year = {1994},
  pages = {285--288}
}

@ARTICLE{Kov02a,
  author = {Tim Kovacs},
  title = {Learning classifier systems resources},
  journal = {Soft Computing},
  year = {2002},
  volume = {6},
  pages = {240--243},
  number = {3--4},
  abstract = {This article lists currently available sources of information on classifier
	systems and classifier systems research, both on-line and in print.
	The need for new resources, and improvements to certain existing
	ones, are suggested.},
  doi = {10.1007/s005000100119},
  file = {Kov02a.pdf:Learning\\Learning Classifier Systems\\Kov02a.pdf:PDF},
  owner = {Richter},
  timestamp = {2008.02.21}
}

@INPROCEEDINGS{KL00,
  author = {Tim Kovacs and Pier Luca Lanzi},
  title = {A bigger learning classifier systems bibliography},
  booktitle = {Proceedings of the International Workshop on Learning Classifier
	Systems (IWLCS 2000)},
  year = {2000},
  volume = {1996},
  series = {LNAI},
  pages = {213--249},
  publisher = {Springer},
  abstract = {With over 600 entries, this is by far the most comprehensive bibliography
	of the machine learning systems introduced by John Holland.},
  owner = {Richter},
  timestamp = {2009.04.06}
}

@MISC{xcslib,
  author = {P. L. Lanzi},
  title = {The XCS library},
  url = {http://xcslib.sourceforge.net}
}

@ARTICLE{Lan08,
  author = {Pier Luca Lanzi},
  title = {Learning classifier systems: {T}hen and now},
  journal = {Evolutionary Intelligence},
  year = {2008},
  volume = {1},
  pages = {63--82},
  number = {1},
  abstract = {Broadly conceived as computational models of cognition and tools for
	modeling complex adaptive systems, later extended for use in adaptive
	robotics, and today also applied to effective classification and
	data-mining -- what has happened to learning classifier systems in
	the last decade? This paper addresses this question by examining
	the current state of learning classifier system research.},
  doi = {10.1007/s12065-007-0003-3},
  keywords = {genetic-based machine learning, learning classifier system, classification,
	reinforcement learning},
  owner = {Richter},
  timestamp = {2008.02.28}
}

@INPROCEEDINGS{Lan98,
  author = {Pier Luca Lanzi},
  title = {Adding Memory to {XCS}},
  booktitle = {Proceedings of the {IEEE} Conference on Evolutionary Computation
	({ICEC}98)},
  year = {1998},
  publisher = {{IEEE} Press},
  url = {citeseer.ist.psu.edu/393845.html}
}

@ARTICLE{LW00,
  author = {Pier Luca Lanzi and Stewart W. Wilson},
  title = {Toward optimal classifier system performance in non-markov environments},
  journal = {Evolutionary Computation},
  year = {2000},
  volume = {8},
  pages = {393--418},
  number = {4},
  abstract = {Wilson's (1994) bit-register memory scheme was incorporated into the
	XCS classifier system and investigated in a series of non-Markov
	environments. Two extensions to the scheme were important in obtaining
	near-optimal performance in the harder environments. The first was
	an exploration strategy in which exploration of external actions
	was probabilistic as in Markov environments, but internal "actions"
	(register settings) were selected deterministically. The second was
	use of a register having more bit-positions than were strictly necessary
	to resolve environmental aliasing. The origins and effects of the
	two extensions are discussed.},
  doi = {10.1162/106365600568239},
  owner = {Richter},
  timestamp = {2009.04.16}
}

@TECHREPORT{lanzi99optimal,
  author = {Pier Luca Lanzi and Stewart W. Wilson},
  title = {Optimal Classifier System Performance in Non-Markovian Environments},
  year = {1999},
  number = {99.36},
  address = {Milan, Italy},
  url = {citeseer.ist.psu.edu/lanzi99optimal.html}
}

@MISC{agentsimulator,
  author = {Clemens Lode},
  title = {AgentSimulator 1.0},
  year = {2009},
  url = {http://www.clawsoftware.de/AgentSimulator10.zip}
}

@INPROCEEDINGS{Lujan2008,
  author = {Lujan, A. and Werner, R. and Boukerche, A.},
  title = {Generation of rule-based adaptive strategies for a collaborative
	virtual simulation environment},
  booktitle = {Proc. IEEE International Workshop on Haptic Audio visual Environments
	and Games HAVE 2008},
  year = {2008},
  pages = {59--64},
}

@INPROCEEDINGS{Butz2003,
  author = {M. V. Butz, K. Sastry and D. E. Goldberg},
  title = {Tournament Selection: Stable Fitness Pressure in XCS},
  booktitle = {Lecture Notes in Computer Science},
  year = {2003},
  pages = {1857-–1869}
}

@INPROCEEDINGS{1102280,
  author = {McMahon,, Alex and Scott,, Dan and Browne,, Will},
  title = {An autonomous explore/exploit strategy},
  booktitle = {GECCO '05: Proceedings of the 2005 workshops on Genetic and evolutionary
	computation},
  year = {2005},
  pages = {103--108},
  address = {New York, NY, USA},
  publisher = {ACM},
  location = {Washington, D.C.}
}

@ARTICLE{Miller95geneticalgorithms,
  author = {Brad L. Miller and Brad L. Miller and David E. Goldberg and David
	E. Goldberg},
  title = {Genetic algorithms, tournament selection, and the effects of noise},
  journal = {Complex Systems},
  year = {1995},
  volume = {9},
  pages = {193--212}
}

@TECHREPORT{miller:1994:CPE,
  author = {Geoffrey F. Miller and Dave Cliff},
  title = {Co-Evolution of Pursuit and Evasion I: Biological and game-Theoretic
	Foundations},
  year = {1994},
  number = {CSRP311},
  institute = {School of Cognitive and Computing Sciences, University of Sussex}
}

@INPROCEEDINGS{RMB+06,
  author = {Urban Richter and Moez Mnif and J{\"{u}}rgen Branke and Christian
	M{\"{u}}ller-Schloer and Hartmut Schmeck},
  title = {Towards a generic observer/controller architecture for Organic Computing},
  booktitle = {INFORMATIK 2006 -- Informatik f{\"u}r Menschen!},
  year = {2006},
  volume = {P-93},
  series = {GI-Edition -- Lecture Notes in Informatics (LNI)},
  pages = {112--119},
  publisher = {Bonner K{\"o}llen Verlag},
  abstract = {Technical scenarios in areas like automotive or production systems
	will increasingly consist of a large number of components cooperating
	in potentially unlimited and dynamically changing networks to satisfy
	the functional requirements of their execution environment. Due to
	the high complexity it will be impossible to explicitly design the
	behaviour of the components for every potentially arising situation.
	Therefore, it will be necessary to leave an adequate degree of freedom
	allowing for a self-organised behaviour. Organic Computing (OC) has
	developed the vision of selforganising systems adapting robustly
	to dynamically changing environments without running out of control.
	This paper focuses on the design of a generic system architecture
	which allows for self-organisation but at the same time enables adequate
	reactions to control the – sometimes completely unexpected – emerging
	global behaviour of these self-organised technical systems.},
  owner = {Richter},
  timestamp = {2006.09.05}
}

@INPROCEEDINGS{Smi83,
  author = {Stephen Frederick Smith},
  title = {Flexible learning of problem solving heuristics through adaptive
	search},
  booktitle = {Proceedings of the 8th International Joint Conference on Artificial
	Intelligence},
  year = {1983},
  abstract = {Noting that the methods employed by existing learning systems are
	often bound to the intended task domain and have little applicability
	outside that domain, this paper considers an alternative learning
	system design that offers greater flexibility without sacrificing
	performance. An operational prototype, constructed around a powerful
	adaptive search technique, is presented and applied to the problem
	of acquiring problem solving heuristics through experience. Some
	performance results obtained with the system in a poker betting domain
	are reported and compared with those of a previously investigated
	learning system in the same domain. It is seen that comparable levels
	of performance are achieved by the two systems, despite the latter's
	dependence on a considerable amount of domain specific knowledge
	for effective operation.},
  owner = {Richter},
  timestamp = {2009.04.07}
}

@PHDTHESIS{Smi80,
  author = {Stephen Frederick Smith},
  title = {A learning system based on genetic adaptive algorithms},
  school = {University of Pittsburgh},
  year = {1980},
  type = {PhD thesis},
  address = {Pittsburgh, PA, United States of America},
  owner = {Richter},
  timestamp = {2009.04.07}
}

@ARTICLE{SB03,
  author = {Christopher Stone and Larry Bull},
  title = {For real! {XCS} with continuous-valued inputs},
  journal = {Evolutionary Computation},
  year = {2003},
  volume = {11},
  pages = {299--336},
  number = {3},
  abstract = {Many real-world problems are not conveniently expressed using the
	ternary representation typically used by Learning Classifier Systems
	and for such problems an intervalbased representation is preferable.
	We analyse two interval-based representations recently proposed for
	XCS, together with their associated operators and find evidence of
	considerable representational and operator bias. We propose a new
	interval-based representation that is more straightforward than the
	previous ones and analyse its bias. The representations presented
	and their analysis are also applicable to other Learning Classifier
	System architectures.
	
	We discuss limitations of the real multiplexer problem, a benchmark
	problem used for Learning Classifier Systems that have a continuous-valued
	representation, and propose a new test problem, the checkerboard
	problem, that matches many classes of real-world problem more closely
	than the real multiplexer.
	
	Representations and operators are compared using both the real multiplexer
	and checkerboard problems and we find that representational, operator
	and sampling bias all affect the performance of XCS in continuous-valued
	environments.},
  file = {SB03.pdf:Learning\\Learning Classifier Systems\\SB03.pdf:PDF},
  owner = {Richter},
  timestamp = {2008.01.16}
}

@ARTICLE{SV00,
  author = {Peter Stone and Manuela Veloso},
  title = {Multi-agent systems: A survey from a machine learning perspective},
  journal = {Autonomous Robots},
  year = {2000},
  volume = {8},
  pages = {345--383},
  number = {3},
  abstract = {Distributed Artificial Intelligence (DAI) has existed as a subfield
	of AI for less than two decades. DAI is concerned with systems that
	consist of multiple independent entities that interact in a domain.
	Traditionally, DAI has been divided into two sub-disciplines: Distributed
	Problem Solving (DPS) focuses on the information management aspects
	of systems with several components working together towards a common
	goal; Multiagent Systems (MAS) deals with behavior management in
	collections of several independent entities, or agents. This survey
	of MAS is intended to serve as an introduction to the field and as
	an organizational framework. A series of general multiagent scenarios
	are presented. For each scenario, the issues that arise are described
	along with a sampling of the techniques that exist to deal with them.
	The presented techniques are not exhaustive, but they highlight how
	multiagent systems can be and have been used to build complex systems.
	When options exist, the techniques presented are biased towards machine
	learning approaches. Additional opportunities for applying machine
	learning to MAS are highlighted and robotic soccer is presented as
	an appropriate test bed for MAS. This survey does not focus exclusively
	on robotic systems. However, we believe that much of the prior research
	in non-robotic MAS is relevant to robotic MAS, and we explicitly
	discuss several robotic MAS, including all of those presented in
	this issue.},
  doi = {10.1023/A:1008942012299},
  file = {SV00.pdf:Multiagent systems\\SV00.pdf:PDF},
  owner = {Richter},
  timestamp = {2008.09.22}
}

@ARTICLE{Takadama,
  author = {K. Takadama and K. Hajiri and T. Nomura and M. Okada and S. Nakasuka
	and K. Shimohara},
  title = {Learning model for adaptive behaviors as an organized group of swarm
	robots},
  journal = {Artificial Life and Robotics},
  year = {1998},
  volume = {2},
  pages = {123--128},
  number = {3},
  publisher = {Springer Japan}
}

@INCOLLECTION{TTS01,
  author = {Keiki Takadama and Takao Terano and Katsunori Shimohara},
  title = {Learning classifier systems meet multi-agent environments},
  booktitle = {Advances in Learning Classifier Systems},
  publisher = {Springer},
  year = {2001},
  volume = {1996},
  series = {LNAI},
  pages = {192--212},
  abstract = {An Organizational-learning oriented Classifier System(OCS) is an extension
	of Learning Classifier Systems (LCSs) to multiagent environments,
	introducing the concepts of organizational learning (OL) in organization
	and management science. Unlike conventional research on LCSs which
	mainly focuses on single agent environments, OCS has an architecture
	for addressing multiagent environments. Through intensive experiments
	on a complex scalable domain, the following implications have been
	revealed: (1) OCS finds good solutions at small computational costs
	in comparison with conventional LCSs, namely the Michigan and Pittsburgh
	approaches; (2) the learning mechanisms at the organizational level
	contribute to improving the performance in multiagent environments;
	(3) an estimation of environmental situations and utilization of
	records of past situations/actions must be implemented at the organizational
	level to cope with non-Markov properties in multiagent environments.},
  keywords = {learning classifier system, multi-agent system, non-Markov environment,
	organizational learning},
  owner = {Richter},
  timestamp = {2008.02.21}
}

@INBOOK{Waldmann,
  chapter = {2},
  pages = {11},
  title = {Stochastische Modelle},
  publisher = {Springer},
  year = {2008},
  author = {K.-H. Waldmann and U. M. Stocker},
  booktitle = {Stochastische Modelle, eine anwendungsorientierte Einführung}
}

@INBOOK{collaborative,
  pages = {586--587},
  title = {Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence},
  publisher = {The MIT Press},
  year = {2000},
  author = {G. Weiss},
  note = {"'Collaboration"'},
  howpublished = {Paperback}
}

@INBOOK{dynamic,
  pages = {30},
  title = {Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence},
  publisher = {The MIT Press},
  year = {2000},
  author = {G. Weiss},
  note = {"'Static vs. Dynamic"'},
  howpublished = {Paperback}
}

@INCOLLECTION{Wil00a,
  author = {Stewart W. Wilson},
  title = {Get Real! {XCS} with continuous-valued inputs},
  booktitle = {Learning classifier systems: From foundations to applications},
  publisher = {Springer},
  year = {2000},
  volume = {1813},
  series = {LNAI},
  pages = {209--219},
  file = {Wil00a.pdf:Learning\\Learning Classifier Systems\\Wil00a.pdf:PDF},
  owner = {Richter},
  timestamp = {2007.10.09}
}

@INPROCEEDINGS{689040,
  author = {Wilson,, Stewart W.},
  title = {Get Real! XCS with Continuous-Valued Inputs},
  booktitle = {Learning Classifier Systems, From Foundations to Applications},
  year = {2000},
  pages = {209--222},
  address = {London, UK},
  publisher = {Springer-Verlag},
  isbn = {3-540-67729-1}
}

@INPROCEEDINGS{xcs2,
  author = {Stewart W. Wilson},
  title = {Generalization in the XCS classifier system},
  booktitle = {Genetic Programming 1998: Proceedings of the Third Annual Conference},
  year = {1998},
  pages = {665--674},
  publisher = {Morgan Kaufmann}
}

@ARTICLE{Wil95,
  author = {Stewart W. Wilson},
  title = {Classifier fitness based on accuracy},
  journal = {Evolutionary Computation},
  year = {1995},
  volume = {3},
  pages = {149--175},
  number = {2},
  owner = {Richter},
  timestamp = {2007.10.09}
}

@ARTICLE{Wil94,
  author = {Stewart W. Wilson},
  title = {{ZCS}: {A} zeroth level classifier system},
  journal = {Evolutionary Computation},
  year = {1994},
  volume = {2},
  pages = {1--18},
  number = {1},
  owner = {Richter},
  timestamp = {2007.10.09}
}

